### Intro

本章总结了多线程编程的常用技术，以及一些最佳实践。

### 不同之处

学习多线程编程面临的最大的思维方式的转变有两点：
- 当前线程可能随时会被切换出去，或者说被抢占（preempt）了。
- 多线程程序中事件的发生顺序不再有全局统一的先后关系

在单CPU 系统中，理论上我们可以通过记录CPU 上执行的指令的先后顺序来
推演多线程的实际交织（interweaving）运行的情况。

在多核系统中，多个线程是并行执行的，我们甚至没有统一的全局时钟来为每个事件编号。在没有适当同步的情况
下，多个CPU 上运行的多个线程中的事件发生先后顺序是无法确定的。

多线程程序的正确性不能依赖于任何一个线程的执行速度，不能通过原地等待
（sleep()）来假定其他线程的事件已经发生，而**必须通过适当的同步**来让当前线程能看到其他线程的事件的结果

### 基本线程原语的选用

本小节给出Posix threads API的一些使用建议：

- 常用的Pthreads函数
- 2个：线程创建和等待结束
- 4个：mutex的创建，销毁，加锁，解锁
- 5个：condition创建，销毁，等待，通知，广播
- 更常使用的是更高层的封装，比如TheadPool, CountdDownLatch
- 酌情使用的Pthreads函数
- pthread_once: 负责多线程的初始化
- pthread_key*: 可以直接使用__thread，本质是提供ThreadLocal storage
- 不推荐使用的Pthreads函数
- pthread_rwlock: chenshuo认为这个锁有可能降低性能，待进一步确定。
- sem*: 和条件变量重合
- pthread_cancel(pthread_kill): 意味着设计出了问题。

对于多线程系统编程，难点不在于学习线程原语，而在于学习如何设计并实现**线程安全**且**高效**的程序。

### c/c++系统库的线程安全性

这一小节，除了学习系统库的线程安全性，我认为chenshuo强调了一个很重要的点就是，对于系统设计者，他们关心的到底是什么？chenshuo这里强调了memory model

>对于标准而言，关键的不是定义线程库，而是规定内存模型（memory model）。特别是规定一个线程对某个共享变量的修改何时能被其他线程看到，这称为内存序（memory ordering）或者内存能见度（memory visibility）

下面我们先简单过一下memory model及其相关概念

#### Memory model

wikipedia给出如下定义

>In computing, a memory model describes the interactions of threads through memory and their shared use of the data.

wiki的解释非常具体(对比cppreference)，简单来说就是约定好线程对于共享数据交互时的行为。那么具体是怎么约定的呢？wiki又进一步给出memory model和编译器优化行为的关系

>A memory model allows a compiler to perform many important optimizations.Compiler optimizations like loop fusion move statements in the program, which can influence the order of read and write operations of potentially shared variables. Changes in the ordering of reads and writes can cause race conditions. 

上面这一段解释说的很明白，memory model允许编译器优化代码的读写指令顺序，而后者的改变可能会导致race condition。注意这里的强调的是可能，因为不是所有读写指令都会影响共享变量，也不是所有影响共享变量的读写指令都会导致race condition。所以memory model本身允许编译器进行代码并没有问题，只是它也需要提供对应的同步工具。

我们接着看wiki给出的说明:

- The memory model specifies synchronization barriers that are established via special, well-defined synchronization operations such as acquiring a lock by entering a synchronized block or method. 
- The memory model stipulates that changes to the values of shared variables only need to be made visible to other threads when such a synchronization barrier is reached. 

这一部分说明memory model提供了barrier工具来进行线程间的同步，同时memory model也约定了同步工具的语义，即当我们使用这些同步工具时，对于共享变量的修改必须对所有线程可见。从下面这张图来说，Core 0更新了shared var，在同步L1/L2 cache的基础上，必须强制同步L3 cache.

<img width="500"  src="img/cpu_hier.png"/>

我们最后看一下这一部分的总结：

>These (memory model)semantics then give optimizing compilers a higher degree of freedom when applying optimizations: the compiler needs to make sure only that the values of (potentially shared) variables at synchronization barriers are guaranteed to be the same in both the optimized and unoptimized code. In particular, reordering statements in a block of code that contains no synchronization barrier is assumed to be safe by the compiler.

这里强调到，memory model首先给了编译器非常大的自由度，让其可以进行代码优化。其次，也约定了编译器的优化限制，即对于共享变量读写指令的优化，必须保证其对于其余线程的可见性。

#### Memory ordering

wikipedia给出如下定义

- Memory ordering describes the order of accesses to computer memory by a CPU. The term can refer either to the memory ordering generated by the compiler during compile time, or to the memory ordering generated by a CPU during runtime.
- In modern microprocessors, memory ordering characterizes the CPU's ability to reorder memory operations – it is a type of out-of-order execution. Memory reordering can be used to fully utilize the bus-bandwidth of different types of memory such as caches and memory banks.
- On most modern uniprocessors memory operations are not executed in the order specified by the program code. In single threaded programs all operations appear to have been executed in the order specified, with all out-of-order execution hidden to the programmer – however in multi-threaded environments (or when interfacing with other hardware via memory buses) this can lead to problems. To avoid problems, memory barriers can be used in these cases.

wiki的解释分了3个层次，层层递进。首先，给出memory ordering的朴素定义，即访存指令的顺序。其次，指出在当下的微处理时代，memory ordering从侧面反映了cpu对于访存指令重排序的能力，即指令重排。这个能力使得cpu可能最大程度的利用总线来提升数据交换的效率。最后，指出了在多线程环境下，指令重排可能会导致为题，但是内存屏障可以解决这个问题。

memory ordering和momory model的关系在于，后者赋予了编译器前者的能力。如果memory model不允许编译器进行优化，那么指令重排也无法发挥作用。

#### Memory barrier

wikipedia给出如下定义

- A memory barrier, also known as a membar, memory fence or fence instruction, is a type of barrier instruction that causes a central processing unit (CPU) or compiler to enforce an ordering constraint on memory operations issued before and after the barrier instruction. This typically means that operations issued prior to the barrier are guaranteed to be performed before operations issued after the barrier.
- Memory barriers are necessary because most modern CPUs employ performance optimizations that can result in out-of-order execution. This reordering of memory operations (loads and stores) normally goes unnoticed within a single thread of execution, but can cause unpredictable behaviour in concurrent programs and device drivers unless carefully controlled. The exact nature of an ordering constraint is hardware dependent and defined by the architecture's memory ordering model. Some architectures provide multiple barriers for enforcing different ordering constraints.

wiki从两个角度来说，其一，内存屏障的作用，即保证在barrier之前的指令执行完了之后，才会执行之后的指令。很明显，这会避免指令重排，起码对于barrier前后的两条指令是这样。其二，强调了内存屏障的必要性，这主要是因为在并发编程环境下，如果不提供屏障工具会导致race condition.

memory barrier和memory model的关系在于，前者是后者提供的工具，来保证在并发编程环境下程序的正确性。

#### std::memory_order

下面我们来简单过一下cpp std::memory_order

When a thread reads a value from a memory location, it may see the initial value, the value written in the same thread, or the value written in another thread. See std::memory_order for details on the order in which writes made from threads become visible to other threads.

很明显，std::memory_barrier约定了多线程对于共享变量的写操作，何时可以被其余线程看见。我们可以认为他约定了指令重排的能力，即实现了memory barrier的能力。

下面我们结合std::memory_order_acquire以及memory_order_release讲一个例子，我们先看一下这两个memory order
- memory_order_acquire:A load operation with this memory order performs the acquire operation on the affected memory location: no reads or writes in the current thread can be reordered before this load. All writes in other threads that release the same atomic variable are visible in the current thread (see Release-Acquire ordering below)
- memory_order_release:A store operation with this memory order performs the release operation: no reads or writes in the current thread can be reordered after this store. All writes in the current thread are visible in other threads that acquire the same atomic variable (see Release-Acquire ordering below) and writes that carry a dependency into the atomic variable become visible in other threads that consume the same atomic (see Release-Consume ordering below).

memory_order_acquire约定读操作的同步机制，即当前读指令之后的指令，不允许指令重排(compiler reordering)到当前读指令之前，保证读指令的完备(读之前的状态不会有改变，避免读不一致，不允许多度)
memory_order_release约定写操作的同步机制，即当前写指令之前的指令，不允许指令重排到当前写指令之后，保证写指令的完备(写之后的状态都执行了，避免写不一致，不允许少写)

接着我们看一个基于dclp的单例实现：

```cpp
Singleton* Singleton::instance() {
  if (pInstance == 0) { // 1st test
    Lock lock;
    if (pInstance == 0) { // 2nd test
      pInstance = new Singleton;
    }
  }
  return pInstance;
}
```

众所周知，上面的实现有问题。问题出在2nd test，```pInstance = new Singleton```这条语句可以分解为以下3步
Step 1: Allocate memory to hold a Singleton object.
Step 2: Construct a Singleton object in the allocated memory.
Step 3: Make pInstance point to the allocated memory.

Of critical importance is the observation that compilers are not constrained to perform these steps in this order! In particular, compilers are sometimes allowed to swap steps 2 and 3.

很明显，发生了指令重排。此时如果线程A执行了(step1->step3)，此时线程B进到instance，那么会出问题。因为线程B发现指针非空，会直接返回。但此时线程A并没有真正的完成构造。

所以，解决问题的核心是：保证step3写之前，step1 and step2均已执行。
下面我们看一个正确的实现(忽略destroy部分)：

```cpp
static T *GetInstance() {
  T *tmp = instance_.load(std::memory_order_relaxed);
  if (tmp == nullptr) {
    std::lock_guard<std::mutex> lock(mutex_);
    tmp = instance_.load(std::memory_order_relaxed);
    if (tmp == nullptr) {
      if (destroyed_.load(std::memory_order_acquire)) {
        LifetimePolicy<T>::DeadReference();
        destroyed_.store(false, std::memory_order_release);
      }
      tmp = CreatePolicy<T>::Create();
      std::atomic_thread_fence(std::memory_order_release);
      instance_.store(tmp, std::memory_order_relaxed);
      LifetimePolicy<T>::ScheduleDestruction(tmp, &DestroySingleton);
    }
  }
  return tmp;
}
static std::atomic<T *> instance_;
```

我们可以发现，在对instance_进行写之前，需要保证内存的分配和对象的构造，即不允许少写。所以使用memory_order_release。
这里有一个注意点是，为什么不使用```instance_.store(tmp, std::memory_order_release)```
而是使用了fence来配合std::memory_order_release

这是因为fence的效果要比基于原子变量的效果更强，具体细节的差异这里不展开。主要需要明白的是保证对于instance_指针的更新，必须在对象创建完成之后才可以。

最后，这里再说一点，原子操作只是保证了对于变量的操作是原子化的，和是否指令重排没有关系。但是，cpp的std::atomic<T>结合了memory_order，可以实现对应的memory barrier功能，这点注意。同时cpp也提供了atomic_thread_fence配合memory_order来实现memory barrier的功能。

#### Allocator

kernel提供了brk/sbrk, mmap来申请内存，但是这3个API均是system call，如果应用程序频繁调用，则会影响性能。glibc提供了ptmalloc作为app与kernel之间的中间层，支持内存申请的功能，本质是池化资源的体现。对于app来说，可以使用malloc/free来进行内存的申请与释放。虽然man manual也提供了malloc/free的说明，但它们并不是system call.

这里单独提到ptmalloc的原因是，内存管理相关的函数，会影响全局状态，所以需要保证线程安全，一般的做法是通过加锁来实现。

#### 线程安全的函数一定能保证代码正确性嘛？

这个不一定，编写线程安全程序的一个难点在于线程安全是不可组合的。这种情况我们之前其实遇到过，比如data race free的函数，不一定没有race condition.一个函数foo调用了两个线程安全的函数，但foo可能不是线程安全的。我们看下面这个demo

```cpp
// 获取伦敦的当前时间
string oldTz = getenv("TZ"); // save TZ, assumeing non-NULL
putenv("TZ=Europe/London"); // set TZ to London
tzset(); // load London time zone

struct tm localTimeInLN;
time_t now = time(NULL); // get time in UTC
localtime_r(&now, &localTimeInLN); // convert to London local time
setenv("TZ", oldTz.c_str(), 1); // restore old TZ
tzset(); // local old time zone
```

tzset函数本身是线程安全的，但是它会改变全局状态(当前时区)，有可能会影响其他代码的转化。

我们不必担心系统调用的线程安全性，因为系统调用对于用户态程序来说是原子的。但是要注意系统调用对于内核状态的改变可能影响其他线程。

### Linux上的线程标识

首先看下面这段代码，其中打印输出的t1,t2可能一样。
```cpp
int main(void)
{
  pthread_t t1, t2;
  pthread_create(&t1, NULL, threadFunc, NULL);
  printf("%lx\n", t1);
  pthread_join(t1, NULL);

  pthread_create(&t2, NULL, threadFunc, NULL);
  printf("%lx\n", t2);
  pthread_join(t2, NULL);
  return 0;
}
```

这里主要涉及到pthread_t这个类型的实现，具体来说。pthread_t 不一定是一个数值类型(整数或指针)，也有可能是一个结构体.
另外，glibc 的Pthreads 实现实际上把pthread_t 用作一个结构体指针（它的类型是unsigned long），指向一块动态分配的内存，而且这块内存是反复使用的。这就造成pthread_t 的值很容易重复

**Pthreads只保证同一进程之内，同一时刻的各个线程的id不同**，因此pthread_t不适合作为线程标识。muduo中建议使用gettid作为线程标识。

```cpp
pid_t gettid() {
  return static_cast<pid_t>(::syscall(SYS_gettid))
}

void CurrentThread::cacheTid() {
  if (t_cachedTid == 0) {  // __thread int t_cachedTid = 0;
      t_cachedTid = gettid();
  }
}

int CurrentThread::tid() {
  if (__builtin_expect(t_cachedTid == 0, 0)) {
    cacheTid();
  }
  return t_cachedTid;
}
```

简单说一下上面的代码，gettid采用了system call，反复调用影响性能。所以用__thread进行了thread storage cache。同时，使用unlikely优化分支预测，性能无忧。

### 线程创建与销毁规则

线程的创建和销毁是编写多线程程序的基本要素，线程的创建比销毁要容易得多，只需要遵循几条简单的原则
- 程序库不应该在未提前告知的情况下创建自己的"背景线程"
- 尽量用相同的方式创建线程，例如muduo::Thread
- 在进入main()函数之前不应该启动线程(这点特别注意！！！)
- 程序中线程的创建最好能在初始化阶段全部完成

这里主要说一下第3点，为什么不能在进入main()之前启动线程，主要是因为这回影响global object的安全构造。关于global object的构造，我们知道
- C++保证在进入main()之前完成全局对象的构造
- 同时，各个编译单元之间的对象构造顺序是不确定的

我们也有一些办法来影响初始化顺序，保证在初始化某个全局对象时使用到的其他全局对象都是构造完成的。但无论如何这些全局对象的构造是依次进行的，都在主线程中完成，无须考虑并发与线程安全
如果其中一个全局对象创建了线程，那就危险了。因为这破坏了初始化全局对象的基本假设。如果子线程访问了还未初始化完成的全局对象，代码可能coredump，同时不好查。

线程的销毁有几种方式
- 自然死亡。从线程主函数返回，线程正常退出。
- 非正常死亡。从线程主函数抛出异常或线程触发segfault信号等非法操作
- 自杀。在线程中调用pthread_exit() 来立刻退出线程
- 他杀。其他线程调用pthread_cancel() 来强制终止某个线程

```pthread_kill```只是向线程发信号，暂不讨论。

**线程正常退出的方式只有一种，即自然死亡。任何从外部强行终止线程的做法和想法都是错的。**其背后的逻辑如下
- 强行终止线程的话（无论是自杀还是他杀），它没有机会清理资源
- 没有机会释放已经持有的锁，其他线程如果再想对同一个mutex 加锁，那么就会立刻死锁。
- 如果非要杀掉一个线程(长时间计算)，可以考虑把这部分代码放到进程里，用杀进程替换杀线程。

如果线程管理可以做成池化资源的形式，则不必担心销毁的问题。

### 善用__thread关键字

由于chenshuo在写muduo的时候，c11尚未流行开来，所以此处讲的还是__thread. c11之后，引入了thread_local keyword，我们先回顾一些这个概念，再看chenshuo给出的使用建议。

Storage duration: Every object has a property called storage duration, which limits the object lifetime. 
- automatic storage duration.
- static storage duration.
- thread storage duration.
- allocated storage duration.

对于此，我们最关心的还是，其对应的物理内存到底在哪里？(哪个段) automatic/static/allocated都非常清楚，分别位于stack/.bss or .data/heap，但是thread_local位于哪里？
根据我之前的总结[thread_local](https://github.com/MaxEntroy/notes/blob/master/public_articles/tech/thread_local.md)，可以确定其位于.tbss or .tbdata

但是对于.tdata/.tbss具体的存储，暂时我还不清楚，但是根据km上的总结，它的实现可能会挤压栈空间，要有这个意识就好。

下面我们看下chenshuo给出的建议：
- __thread存取效率堪比全局变量，效率高
- __thread只能修饰POD类型
- __thread变量的初始化，只能用编译期常量
- __thread只能修改全局变量 and 函数内静态变量(注意，全局or函数内，是作用域，和lifetime没有关系，不要混淆)

关于第3点，参见如下代码
```cpp
__thread string t_obj1("Chen Shuo"); // 错误，不能调用对象的构造函数
__thread string* t_obj2 = new string; // 错误，初始化必须用编译期常量
__thread string* t_obj3 = NULL; // 正确，但是需要手工初始化并销毁对象
```

关于__thread的使用场景
- __thread是每个线程有一份独立实体，各个线程的变量值互不干扰，这是主要用途。wiki上的引子就是这个，讲了unix errno在多线程环境下面临的问题。
- 它还可以修饰那些"值可能会变，带有全局性，但又不值得使用全局锁保护的变量"。这个wiki上的第二个例子就是，一个全局counter，多线程写，加锁。不如先用thread_local，最后merge

关于非POD类型，muduo封装了ThreadLocal<T>类支持非POD类型，线程退出时进行销毁。其大致封装原理如下(以posix implementation为例)
- In the Pthreads API, memory local to a thread is designated with the term Thread-specific data.
- The functions pthread_key_create and pthread_key_delete are used respectively to create and delete a key for thread-specific data. 
- The type of the key is explicitly left opaque and is referred to as pthread_key_t
- This key can be seen by all threads. In each thread, the key can be associated with thread-specific data via pthread_setspecific. The data can later be retrieved using pthread_getspecific
- In addition pthread_key_create can optionally accept a destructor function that will automatically be called at thread exit

```cpp
template<typename T>
class ThreadLocal {
 public:
  ThreadLocal() { MCHECK(pthread_key_create(&pkey_, ThreadLocal::dtor)); }

  ~ThreadLocal() { MCHECK(pthread_key_delete(pkey_)); }

  ThreadLocal(const ThreadLocal&) = delete;
  ThreadLocal& operator=(const ThreadLocal&) = delete;

  T& value() {
    T* per_thread_val = static_cast<T*>(pthread_getspecific(pkey_));
    if (!per_thread_val) {
      T* val = new T();
      MCHECK(pthread_setspecific(pkey_, val));
      per_thread_val = val;
    }
    return *per_thread_val;
  }

 private:
  static void dtor(void* x) {
    T* obj = static_cast<T*>(x);
    typedef char T_must_be_complete_type[sizeof(T) == 0 ? -1 : 0];
    T_must_be_complete_type dummy; (void) dummy;
    delete obj;
  }

 private:
  pthread_key_t pkey_;
};
```

对于__thread/ThreadLocal<T>编码时最大的便利之处在于**一处定义，多个实例**。回想non-thread-local var，都是需要几个，定义几个。但是tls的方便之处在于，定义/操作的时候，只定义/操作一个。
不同的线程会生成各自的独一份存储。线程读写的时候，虽然操作的是同一个变量，但实际操作的是不同线程的tls var.

看下面这部分代码片段，test_obj定义/操作均是针对同一个对象，但实际上操作的是不同的tls var,因而也不用加锁。

```cpp
mymuduo::ThreadLocal<Foo> test_obj;

void Print() {
  printf("tid=%d, addr=%p, name=%s\n",
         ::mymuduo::CurrentThread::Tid(),
         &test_obj.value(),
         test_obj.value().Name().c_str());
}

void* ThreadRoutine1(void* arg) {
  Print();
  test_obj.value().SetName("thread routine1");
  Print();

  (void) arg;
  return nullptr;
}

void* ThreadRoutine2(void* arg) {
  Print();
  test_obj.value().SetName("thread routine2");
  Print();

  (void) arg;
  return nullptr;
}
```

下面我们讨论以下__thread和c11之后标准提供的thread_local的异同

- 修饰变量种类
  - __thread:global, file-scoped static, function-scoped static, or static data member of a class. It may not be applied to block-scoped automatic or non-static data member
  - thread_local:本质上和__thread一样，但是其可以修饰block-scoped automatic var，但是根据std我们知道When thread_local is applied to a variable of block scope the storage-class-specifier static is implied
- 修饰变量类型
  - __thread: 仅支持POD，不支持non-local，原因在于无法主动调用ctor/dtor.但是可以通过ptr to non-local解决，后者需要programmer自己管理heap
  - thread_local: 无限制
- 初始化
  - __thread: constant-expression
  - thread_local: default initialization(不一定常量)

下面着重说一下thread_local penalty, 这点__thread没有

So the run-time penalty is that, every reference of the thread_local variable will become a function call(wrappter).This wrapper is not needed for in every use case of thread_local though. This can be revealed from decl2.c. The wrapper is generated only when
- It is extern (the example shown above), or
- The type has a non-trivial destructor (which is not allowed for __thread variables), or
- The type variable is initialized by a non-constant-expression (which is also not allowed for __thread variables).

In all other use cases, it behaves the same as __thread. That means, unless you have some extern __thread variables, you could replace all __thread by thread_local without any loss of performance.

### Ref
[https://gcc.gnu.org/onlinedocs/gcc-4.7.2/gcc/Thread_002dLocal.html](https://gcc.gnu.org/onlinedocs/gcc-4.7.2/gcc/Thread_002dLocal.html)
[What is the performance penalty of C++11 thread_local variables in GCC 4.8?](https://stackoverflow.com/questions/13106049/what-is-the-performance-penalty-of-c11-thread-local-variables-in-gcc-4-8)